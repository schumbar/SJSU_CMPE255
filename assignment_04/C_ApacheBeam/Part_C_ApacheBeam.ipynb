{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNocp1IyJmjS2cXX4zbWMmN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schumbar/SJSU_CMPE255/blob/main/assignment_04/C_ApacheBeam/Part_C_ApacheBeam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 04: Apache Beam Data Engineering Assignment\n",
        "### Part C: Apache Beam Features\n",
        "By Shawn Chumbar\n",
        "  \n",
        "Please note that I have used ChatGPT to assist me with this assignment.\n",
        "You can view all of the code that I have written for each task within the **Apache Beam Code** section. Alternatively, I have also written up a summary of each step within the **Conclusion** section with supporting code snippets."
      ],
      "metadata": {
        "id": "AjoAXDPL4Xr8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tasks:\n",
        "1. Composite transform\n",
        "2. Pipeline IO\n",
        "3. triggers\n",
        "4. windowing\n",
        "5. ParDo\n",
        "\n",
        "Sources:\n",
        "1. [About Beam ML](https://beam.apache.org/documentation/ml/about-ml/)\n",
        "2. [Get started with AI/ML pipelines](https://beam.apache.org/documentation/ml/overview/)\n",
        "3. [Use RunInference with Sklearn](https://beam.apache.org/documentation/transforms/python/elementwise/runinference-sklearn/)\n",
        "4. [Apache Beam Tutorial](https://www.macrometa.com/event-stream-processing/apache-beam-tutorial)\n",
        "5. [Intro to Apache Beam - Python](https://colab.research.google.com/drive/1qrqbpRpfMtwosjcZQ3_qAWvBCXtzs-8D?usp=sharing)\n",
        "\n",
        "Dataset Link:\n",
        "[Healthcare Insurance](https://www.kaggle.com/datasets/willianoliveiragibin/healthcare-insurance)"
      ],
      "metadata": {
        "id": "ZBbRRq-z_Abs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install apache_beam"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJJZeaiSRvgT",
        "outputId": "9c0c0c2e-68b6-4c67-fd9d-abb13389d14a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting apache_beam\n",
            "  Downloading apache_beam-2.51.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting crcmod<2.0,>=1.7 (from apache_beam)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting orjson<4,>=3.9.7 (from apache_beam)\n",
            "  Downloading orjson-3.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1 (from apache_beam)\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2.2.1)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache_beam)\n",
            "  Downloading fastavro-1.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasteners<1.0,>=0.3 (from apache_beam)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (1.59.0)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache_beam)\n",
            "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (0.22.0)\n",
            "Collecting js2py<1,>=0.74 (from apache_beam)\n",
            "  Downloading Js2Py-0.74-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.25.0,>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (1.23.5)\n",
            "Collecting objsize<0.7.0,>=0.6.1 (from apache_beam)\n",
            "  Downloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (23.2)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache_beam)\n",
            "  Downloading pymongo-4.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (671 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m671.3/671.3 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (1.22.3)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.0,!=4.24.1,!=4.24.2,<4.25.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (3.20.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2023.3.post1)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2023.6.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (4.5.0)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache_beam)\n",
            "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow<12.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (9.0.0)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache_beam)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache_beam) (1.16.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<0.23.0,>=0.8->apache_beam) (3.1.1)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache_beam) (5.1)\n",
            "Collecting pyjsparser>=2.5.1 (from js2py<1,>=0.74->apache_beam)\n",
            "  Downloading pyjsparser-2.7.1.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache_beam)\n",
            "  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache_beam) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache_beam) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache_beam) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache_beam) (2023.7.22)\n",
            "Building wheels for collected packages: crcmod, dill, hdfs, pyjsparser, docopt\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31407 sha256=1e9e500222a28574377980356e901d5c7ba672a421ed2639fe614192a90874fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78542 sha256=c167a7ab33ba9a2cf5b1a43663f8c87d3c3afb62ef6237c8f25585534f710d40\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34325 sha256=8232985cbdc8b52a0d4a828ba1780473bcbb95842f3da5335e3eeb462d57543e\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
            "  Building wheel for pyjsparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyjsparser: filename=pyjsparser-2.7.1-py3-none-any.whl size=25982 sha256=707f8b394004949c2088ab19d94c24f75e6161850733deb525b38e71bf581ebe\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/81/26/5956478df303e2bf5a85a5df595bb307bd25948a4bab69f7c7\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=f48530843e31af92253549a422112522d0c924b6755cc2c674c410a542457446\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built crcmod dill hdfs pyjsparser docopt\n",
            "Installing collected packages: pyjsparser, docopt, crcmod, zstandard, orjson, objsize, js2py, fasteners, fastavro, dnspython, dill, pymongo, hdfs, apache_beam\n",
            "Successfully installed apache_beam-2.51.0 crcmod-1.7 dill-0.3.1.1 dnspython-2.4.2 docopt-0.6.2 fastavro-1.8.4 fasteners-0.19 hdfs-2.7.3 js2py-0.74 objsize-0.6.1 orjson-3.9.9 pyjsparser-2.7.1 pymongo-4.5.0 zstandard-0.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpCadrD04NkC",
        "outputId": "9a58f510-dff6-441b-bdc9-602247a4f289"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import apache_beam as beam\n",
        "from apache_beam.options.pipeline_options import PipelineOptions"
      ],
      "metadata": {
        "id": "WhsKw72GPgsK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets\n",
        "file_path = '/content/drive/MyDrive/SJSU/CMPE_255/assignment_04/datasets/insurance.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pIu9ctu0PdzJ",
        "outputId": "927bc1d9-7b1e-4937-dbff-34e045f8d25e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age     sex     bmi  children smoker     region      charges\n",
              "0   19  female  27.900         0    yes  southwest  16884.92400\n",
              "1   18    male  33.770         1     no  southeast   1725.55230\n",
              "2   28    male  33.000         3     no  southeast   4449.46200\n",
              "3   33    male  22.705         0     no  northwest  21984.47061\n",
              "4   32    male  28.880         0     no  northwest   3866.85520"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-96f238c0-d4cf-4951-805a-784d1131ce9e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96f238c0-d4cf-4951-805a-784d1131ce9e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-96f238c0-d4cf-4951-805a-784d1131ce9e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-96f238c0-d4cf-4951-805a-784d1131ce9e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f06fa8ad-b9a0-410f-b48e-bb98d40168f6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f06fa8ad-b9a0-410f-b48e-bb98d40168f6')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f06fa8ad-b9a0-410f-b48e-bb98d40168f6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Manual EDA"
      ],
      "metadata": {
        "id": "Tvthry-LlFyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPfXfepmP1Yw",
        "outputId": "3aad7ef2-5974-40da-8a14-a1ac83daa025"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This data seems to have the following columns:\n",
        "* Age\n",
        "* sex\n",
        "* bmi\n",
        "* children\n",
        "* smoker\n",
        "* region\n",
        "* charges\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zD4xnsKPlH0C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apache Beam Code"
      ],
      "metadata": {
        "id": "8aKGfGt67OwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Function to parse each CSV row into a dictionary\n",
        "def parse_csv(line):\n",
        "    fields = line.split(',')\n",
        "    return {\n",
        "        'age': int(fields[0]),\n",
        "        'sex': fields[1],\n",
        "        'bmi': float(fields[2]),\n",
        "        'children': int(fields[3]),\n",
        "        'smoker': fields[4],\n",
        "        'region': fields[5],\n",
        "        'charges': float(fields[6])\n",
        "    }\n",
        "\n",
        "# Function to format results into a CSV string. It now accepts two parameters: key and value.\n",
        "def to_csv_string(key, value):\n",
        "    # Assuming you want to write the key and value separated by a comma\n",
        "    return f\"{key},{value}\"\n",
        "\n",
        "\n",
        "# Composite transform to calculate average charge by a grouping key (e.g., smoker status)\n",
        "class CalculateAverageChargeByGroup(beam.PTransform):\n",
        "    def __init__(self, group_key):\n",
        "        self.group_key = group_key\n",
        "\n",
        "    def expand(self, pcoll):\n",
        "        return (\n",
        "            pcoll\n",
        "            | 'Extract Key Value' >> beam.Map(lambda elem: (elem[self.group_key], elem['charges']))\n",
        "            | 'Group By Key' >> beam.GroupByKey()\n",
        "            | 'Calculate Average' >> beam.Map(lambda elem: (elem[0], sum(elem[1]) / len(elem[1])))\n",
        "        )\n",
        "\n",
        "# Define the pipeline\n",
        "pipeline_options = PipelineOptions()\n",
        "with beam.Pipeline(options=pipeline_options) as p:\n",
        "    csv_lines = (\n",
        "        p\n",
        "        | 'Read from CSV' >> beam.io.ReadFromText(file_path, skip_header_lines=1)\n",
        "        | 'Parse CSV to Dict' >> beam.Map(parse_csv)\n",
        "    )\n",
        "\n",
        "    # Calculate average charge by 'smoker' status as an example\n",
        "    average_charge_by_smoker = (\n",
        "        csv_lines\n",
        "        | 'Average Charge by Smoker' >> CalculateAverageChargeByGroup('smoker')\n",
        "    )\n",
        "    # Convert the results to CSV format and write them to a file\n",
        "    (\n",
        "        average_charge_by_smoker\n",
        "        | 'Format as CSV' >> beam.MapTuple(to_csv_string)\n",
        "        | 'Write to File' >> beam.io.WriteToText('/content/drive/MyDrive/SJSU/CMPE_255/assignment_04/datasets/output.csv')\n",
        "    )\n"
      ],
      "metadata": {
        "id": "phL4RIBuDaxp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "508dc4c5-0813-431a-bbd1-2414d778ad09"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-4775001c-b65b-43e7-b021-29458c767e12.json']\n",
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-4775001c-b65b-43e7-b021-29458c767e12.json']\n",
            "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###"
      ],
      "metadata": {
        "id": "ewbpPpIIBHzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/SJSU/CMPE_255/assignment_04/datasets/insurance.csv'"
      ],
      "metadata": {
        "id": "IQyDfUgO9H1a"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n",
        "from apache_beam.transforms.window import FixedWindows\n",
        "import logging\n",
        "\n",
        "# Custom ParDo class to filter data based on some condition.\n",
        "class FilterData(beam.DoFn):\n",
        "    def process(self, element):\n",
        "        try:\n",
        "            if float(element['charges']) > 1000:  # Assuming 'charges' is a valid field\n",
        "                yield element\n",
        "        except ValueError as e:\n",
        "            logging.error(f\"Error processing {element}: {e}\")\n",
        "            # Consider how you want to handle exceptions in your pipeline.\n",
        "\n",
        "# Custom composite transform that combines multiple transforms\n",
        "class ComputeAverageCharge(beam.PTransform):\n",
        "    def expand(self, input_coll):\n",
        "        return (\n",
        "            input_coll\n",
        "            | 'Extract and Convert Data' >> beam.Map(lambda elem: (elem['region'], float(elem['charges'])))\n",
        "            | 'Combine by Key' >> beam.CombinePerKey(sum)  # This is a simplistic approach for the sake of demonstration.\n",
        "        )\n",
        "\n",
        "# Function to safely convert CSV lines to dictionaries\n",
        "def safe_dict_read(line, headers):\n",
        "    try:\n",
        "        values = line.split(',')\n",
        "        return dict(zip(headers, values))  # Pairing headers with corresponding values\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Failed to parse line: {line}, Error: {e}\")\n",
        "        return None  # Returning None to indicate failure of parsing this line\n",
        "\n",
        "def run():\n",
        "    # Defining the pipeline options\n",
        "    pipeline_options = PipelineOptions(\n",
        "        runner='DirectRunner'  # using a direct runner for simplicity\n",
        "    )\n",
        "\n",
        "    # Define the CSV headers\n",
        "    csv_headers = ['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges']\n",
        "\n",
        "    with beam.Pipeline(options=pipeline_options) as p:\n",
        "        (\n",
        "            p\n",
        "            | 'Read from CSV' >> beam.io.ReadFromText(file_path, skip_header_lines=1)  # Reading data from the source\n",
        "            | 'Convert to dict' >> beam.Map(lambda line: safe_dict_read(line, csv_headers))\n",
        "            | 'Filter records' >> beam.ParDo(FilterData())  # Using ParDo for a custom filtering operation\n",
        "            | 'Window into' >> beam.WindowInto(FixedWindows(60))  # Windowing the data into fixed intervals\n",
        "            | 'Calculate average charge' >> ComputeAverageCharge()  # Applying the custom composite transform\n",
        "            | 'Write results' >> beam.Map(print)  # Writing the results to the console or another sink\n",
        "        )\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    logging.getLogger().setLevel(logging.INFO)\n",
        "    run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2W9fJmf9B8-",
        "outputId": "399667b2-ad33-4f69-e336-5d532acff6d0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-4775001c-b65b-43e7-b021-29458c767e12.json']\n",
            "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function annotate_downstream_side_inputs at 0x7cdc8c180310> ====================\n",
            "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function fix_side_input_pcoll_coders at 0x7cdc8c180430> ====================\n",
            "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function pack_combiners at 0x7cdc8c180940> ====================\n",
            "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function lift_combiners at 0x7cdc8c1809d0> ====================\n",
            "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function expand_sdf at 0x7cdc8c180b80> ====================\n",
            "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function expand_gbk at 0x7cdc8c180c10> ====================\n",
            "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function sink_flattens at 0x7cdc8c180d30> ====================\n",
            "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function greedily_fuse at 0x7cdc8c180dc0> ====================\n",
            "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function read_to_impulse at 0x7cdc8c180e50> ====================\n",
            "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function impulse_to_input at 0x7cdc8c180ee0> ====================\n",
            "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function sort_stages at 0x7cdc8c181120> ====================\n",
            "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function add_impulse_to_dangling_transforms at 0x7cdc8c181240> ====================\n",
            "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function setup_timer_mapping at 0x7cdc8c181090> ====================\n",
            "INFO:apache_beam.runners.portability.fn_api_runner.translations:==================== <function populate_data_channel_coders at 0x7cdc8c1811b0> ====================\n",
            "INFO:apache_beam.runners.worker.statecache:Creating state cache with size 104857600\n",
            "INFO:apache_beam.runners.portability.fn_api_runner.worker_handlers:Created Worker handler <apache_beam.runners.portability.fn_api_runner.worker_handlers.EmbeddedWorkerHandler object at 0x7cdc87e8abc0> for environment ref_Environment_default_environment_1 (beam:env:embedded_python:v1, b'')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('southwest', 4012754.647620001)\n",
            "('southeast', 5363689.763290002)\n",
            "('northwest', 4035711.9965399993)\n",
            "('northeast', 4343668.583308999)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "Please see the section below for proof that we performed all of the things outlined in the Assignment prompt. I have provided code snippets of code that I have written showcasing that I have performed the following Apache Beam tasks:\n",
        "1. Composite Transform\n",
        "2. Pipeline I/O\n",
        "3. Triggers\n",
        "4. Windowing\n",
        "5. ParDo"
      ],
      "metadata": {
        "id": "OuLkf0AnCV46"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Composite Transform\n",
        "\n",
        "A composite transform is essentially a combination of multiple transforms encapsulated into one reusable component. In the script, `ComputeAverageCharge` is a composite transform. It's a class that inherits from `beam.PTransform` and overrides the `expand` method to provide its transformation logic.\n",
        "\n",
        "Here's the relevant code snippet:\n",
        "\n",
        "```python\n",
        "class ComputeAverageCharge(beam.PTransform):\n",
        "    def expand(self, input_coll):\n",
        "        # In this transform, we're combining multiple steps:\n",
        "        # 1. Extracting and converting data from each element.\n",
        "        # 2. Combining data by key (in this case, by 'region').\n",
        "        return (\n",
        "            input_coll\n",
        "            | 'Extract and Convert Data' >> beam.Map(lambda elem: (elem['region'], float(elem['charges'])))\n",
        "            | 'Combine by Key' >> beam.CombinePerKey(sum)  # Summing up the charges for each region\n",
        "        )\n",
        "```"
      ],
      "metadata": {
        "id": "v5M5jUXzB_dn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pipeline I/O\n",
        "\n",
        "Pipeline I/O refers to the input and output operations within a pipeline. This is where we read data into our pipeline and output the processed data from our pipeline.\n",
        "\n",
        "In the script, we handle input by reading from a CSV file and output by printing the results to the console (though in a real-world scenario, you might write to a database, a file system, or some other storage service).\n",
        "\n",
        "```python\n",
        "(\n",
        "    p\n",
        "    | 'Read from CSV' >> beam.io.ReadFromText('/path/to/your/insurance_sample.csv', skip_header_lines=1)  # Input operation\n",
        "    # ... [data processing steps] ...\n",
        "    | 'Write results' >> beam.Map(print)  # Output operation\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "0VXNMNtfCxKu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Triggers\n",
        "\n",
        "In the context of Apache Beam, triggers determine when to emit the aggregated results of each window (in streaming, primarily). The script you have is more suited for batch processing and doesn't explicitly define a custom trigger, so it uses Beam's default trigger, which emits the result of each window when it's considered complete.\n",
        "\n",
        "If we were to use triggers in a streaming context, they would be defined as part of the windowing strategy, like so:\n",
        "\n",
        "```python\n",
        "| 'Window' >> beam.WindowInto(\n",
        "      FixedWindows(60),\n",
        "      trigger=AfterWatermark(),  # This is where you'd specify the trigger.\n",
        "      accumulation_mode=AccumulationMode.DISCARDING)\n",
        "```"
      ],
      "metadata": {
        "id": "APd9NYb3Czwq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Windowing\n",
        "\n",
        "Windowing is the mechanism for collecting and grouping data into finite sets or windows. In the provided script, we use fixed-time windowing, which means events are grouped into windows of a set duration.\n",
        "\n",
        "```python\n",
        "| 'Window into' >> beam.WindowInto(FixedWindows(60))  # Windowing the data into fixed intervals of 60 seconds\n",
        "```"
      ],
      "metadata": {
        "id": "g_9H4O81C0Is"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ParDo\n",
        "\n",
        "ParDo is a Beam transform for generic parallel processing. A `ParDo` takes a `DoFn` object that defines the processing function that should be applied to each element of the input `PCollection`.\n",
        "\n",
        "In the script, `FilterData` is a `DoFn` applied to the pipeline using `ParDo`, which filters the elements based on a specific condition.\n",
        "\n",
        "```python\n",
        "class FilterData(beam.DoFn):\n",
        "    def process(self, element):\n",
        "        # ... [your filtering logic] ...\n",
        "\n",
        "# Applying the ParDo in the pipeline\n",
        "| 'Filter records' >> beam.ParDo(FilterData())\n",
        "```\n",
        "\n",
        "This `ParDo` operation is where each element is individually processed (filtered) through the user-defined function in `FilterData`."
      ],
      "metadata": {
        "id": "CgVBRdSLC2Vb"
      }
    }
  ]
}