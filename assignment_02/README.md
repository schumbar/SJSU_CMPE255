# Assignment 2 
Shawn Chumbar
CMPE 255

## Part 1: JADBio

### Summary
In this assignment, we used JADBio to apply machine learning to a dataset. JADBio is a robus AutoML platform that focuses on analyzing 
medical datasets. It makes it easy and affordable for datascientists and life-science professional to use data science to 
accomplish the data discovery process. 

### Deliverables
Please see below for the this part's assignment deliverables (NOTE: All files are under the **assignment_02/part_01** folder):
1. 01_analysis_results.png: Screenshot showing the analysis results page. 
2. 02_analysis_results.png: Screenshot showing the Aggressive Feature Selection tab of the analysis results page. 
3. 04_predictor_values.png: Screenshot showing predictor values.
4. 05_predictor_values.png Screenshot showing using the predictor value of 2.
5. 06_graph.png: Graph showing the distribution of each performance metric.
6. 07_plot.png: A plot.
7. Report-JADBio Automated Machine Learning Platform - AutoML.pdf: JADBio Description of Performed Analysis and Results summary
8. Report-analysis_report.md: Markdown version of the JADBio Automated Machine Learning report (file described in number 7)
9. dataset_Obesity_among_children_and_adolescents_aged_2_19_years__by_selected_characteristics__United_States.csv: Dataset that was used for this part of the assignment. 
10. TODO: [Youtube Video Link](youtube.com)

### Datasets
The dataset described in this project was retrieved from kaggle.

### References
1. https://jadbio.com/extract-knowledge-from-your-data-with-jadbio-automl-free/
2. https://www.youtube.com/channel/UCuvLxmd6r7uQJqzfv1sYHwg/videos
3. https://www.youtube.com/watch?v=CgFD8ZJeYOs&list=PLiUEs1Sfl_PWAoTZ2h9KtWcwD8flSkxBM&ab_channel=JADBio 
4. Most importantly, all the videos within the How to use JADBio guide (reference number 3).

## Part 2: PyCaret and Gradio 

### Summary
In this part of the assignment, we used PyCaret and Gradio to perform low code data mining. We had to find a kaggle dataset and implement, run, and provide output of the colabs of pycaret. 
We were instructed to use the full automl capabilities of pyCaret.

### Deliverables
NOTE: All of the project deliverables mentioned in this section live under the **assignment_02/part_02** folder. Please see below for the list of deliverables for this part of assignment 2:
1. CMPE255_Assignment_02.ipynb: google colab notebook containing all of the different types of ML models that were ran.
2. datasets folder: This folder contains all of the datasets that were used within this google colab. 


### Datasets
**NOTE: Some of the datasets that were used in this project were created using ChatGPT.** 
ChatGPT was used to created the following datasets:
1. abalone_test.csv
2. ice_cream_sales.csv
3. network_traffic_data.csv
4. seeds_dataset.csv
5. syntetic_test_data.csv

Please see below for a list of datasets that were obtained from Kaggle:
1. [abalone.csv](https://www.kaggle.com/datasets/rodolfomendes/abalone-dataset)
2. [bmi.csv](https://www.kaggle.com/datasets/rukenmissonnier/age-weight-height-bmi-analysis)
3. [diabetes.csv](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database)
4. [KC_House_Data.csv](https://www.kaggle.com/datasets/astronautelvis/kc-house-data)

### References
1. https://www.youtube.com/watch?v=NbBoZQZ3bxo&ab_channel=GregHogg
2. https://www.youtube.com/watch?v=4JyYhbW6eCA&ab_channel=PyCaret
3. https://www.gradio.app/docs/interface 
4. https://pycaret.gitbook.io/docs/get-started/quickstart#classification
5. https://medium.com/nerd-for-tech/build-a-machine-learning-model-with-pycaret-and-corresponding-user-interface-with-gradio-57ff09b7d262
6. https://pycaret.gitbook.io/docs/get-started/tutorials 
7. I also used ChatGPT for data preprocessing so that the data would be ready to use with pandas.